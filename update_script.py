# update_script.py
# åŠŸèƒ½ï¼šè‡ªåŠ¨è§£å¯†ã€å¯¹æ¯”ã€æ›´æ–°ç½‘æ˜“æ•æ„Ÿè¯ï¼Œå¹¶ç”Ÿæˆå˜åŒ–æŠ¥å‘Š
# ç”¨é€”ï¼šé…åˆ GitHub Actions è‡ªåŠ¨åŒ–è¿è¡Œ

import re
import json
import base64
import requests
from Crypto.Cipher import ARC4
import os
from deepdiff import DeepDiff
from hashlib import md5
from datetime import datetime

# ========== é…ç½® ==========
CACHE_FILE = "last_urls.json"        # ç¼“å­˜ä¸Šä¸€æ¬¡çš„ URL å’Œå“ˆå¸Œ
CHANGELOG_MD = "CHANGELOG.md"        # äººç±»å¯è¯»çš„å˜åŒ–æŠ¥å‘Š
CHANGELOG_JSON = "changes.json"      # æœºå™¨å¯è¯»çš„ç»“æ„åŒ–å·®å¼‚
GITHUB_OWNER = "daijunhaoMinecraft"
GITHUB_REPO = "NeteaseSensitiveWordsProject"
GITHUB_BRANCH = "main"

# ========== å·¥å…·å‡½æ•° ==========

def decode_pcre_unicode_in_obj(obj):
    """
    Recursively decode strings with PCRE-style Unicode escape sequences (e.g., \\x{abcd}).
    """
    if isinstance(obj, dict):
        return {k: decode_pcre_unicode_in_obj(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [decode_pcre_unicode_in_obj(elem) for elem in obj]
    elif isinstance(obj, str):
        def replace_match(match):
            hex_code = match.group(1)
            return chr(int(hex_code, 16))
        return re.sub(r'\\x\{([0-9a-fA-F]+)\}', replace_match, obj)
    else:
        return obj

def decrypt_content(encrypted_content: bytes, key: str) -> dict:
    """è§£å¯†å¹¶è¿”å›å­—å…¸"""
    try:
        encrypted_data = base64.b64decode(encrypted_content)
        cipher = ARC4.new(key.encode('utf-8'))
        decrypted_data = cipher.decrypt(encrypted_data)
        raw_text = decrypted_data.decode('utf-8')
        parsed = json.loads(raw_text)
        return decode_pcre_unicode_in_obj(parsed)
    except Exception as e:
        print(f"[ERROR] è§£å¯†å¤±è´¥: {e}")
        raise

def load_cache():
    """åŠ è½½ä¸Šä¸€æ¬¡çš„çŠ¶æ€ï¼ˆURL + å“ˆå¸Œï¼‰"""
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            for key in ["x19_url", "g79_url", "x19_hash", "g79_hash"]:
                if key not in data:
                    data[key] = None
            return data
        except Exception as e:
            print(f"[WARN] æ— æ³•è¯»å–ç¼“å­˜æ–‡ä»¶: {e}")
    return {"x19_url": None, "g79_url": None, "x19_hash": None, "g79_hash": None}

def save_cache(x19_url, g79_url, x19_hash, g79_hash):
    """ä¿å­˜å½“å‰çŠ¶æ€"""
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump({
            "x19_url": x19_url,
            "g79_url": g79_url,
            "x19_hash": x19_hash,
            "g79_hash": g79_hash,
            "updated_at": datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=4)

def hash_json(data):
    """ç”Ÿæˆ JSON å†…å®¹çš„ç¨³å®šå“ˆå¸Œ"""
    return md5(json.dumps(data, sort_keys=True, ensure_ascii=False, separators=(',', ':')).encode('utf-8')).hexdigest()

def compare_words_by_content(old_data, new_data):
    """
    é€šè¿‡æ¯”è¾ƒæ­£åˆ™è¡¨è¾¾å¼çš„å†…å®¹è€Œä¸æ˜¯ä¸ç¨³å®šçš„IDæ¥æ‰¾å‡ºå·®å¼‚ã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«'added', 'removed', 'modified'çš„å­—å…¸ã€‚
    """
    changes = {"added": [], "removed": [], "modified": {}}

    old_regex_dict = old_data.get("regex", {}).get("nickname", {})
    new_regex_dict = new_data.get("regex", {}).get("nickname", {})

    old_content_to_id = {v: k for k, v in old_regex_dict.items()}
    new_content_to_id = {v: k for k, v in new_regex_dict.items()}

    old_contents = set(old_content_to_id.keys())
    new_contents = set(new_content_to_id.keys())

    added_contents = new_contents - old_contents
    removed_contents = old_contents - new_contents

    for content in sorted(list(added_contents)):
        changes["added"].append({"id": new_content_to_id[content], "value": content})

    for content in sorted(list(removed_contents)):
        changes["removed"].append({"id": old_content_to_id[content], "value": content})

    old_data_copy = json.loads(json.dumps(old_data))
    new_data_copy = json.loads(json.dumps(new_data))
    if "nickname" in old_data_copy.get("regex", {}): del old_data_copy["regex"]["nickname"]
    if "nickname" in new_data_copy.get("regex", {}): del new_data_copy["regex"]["nickname"]
    
    other_diffs = DeepDiff(old_data_copy, new_data_copy, ignore_order=True)
    if other_diffs:
        changes["modified"] = other_diffs.to_dict()

    if not changes["added"] and not changes["removed"] and not changes["modified"]:
        return None
    
    return changes

# ã€ä¿®å¤ã€‘ç°åœ¨åªæœ‰åœ¨æœ‰å˜åŒ–æ—¶æ‰å†™å…¥æ–‡ä»¶
def generate_and_save_report(differences):
    """
    æ ¹æ®å·®å¼‚ç”ŸæˆæŠ¥å‘Šã€‚åªæœ‰åœ¨æœ‰å®é™…å˜åŒ–æ—¶æ‰å†™å…¥æ–‡ä»¶ã€‚
    :param differences: [(filename, diff_dict, old_data, new_data), ...]
    :return: (bool) æ˜¯å¦ç”Ÿæˆäº†æ–°æŠ¥å‘Š
    """
    if not any(d[1] for d in differences):
        print("[INFO] æœªæ£€æµ‹åˆ°ä»»ä½•å†…å®¹å˜åŒ–ï¼Œè·³è¿‡ç”ŸæˆæŠ¥å‘Šã€‚")
        return False

    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    md_content = f"# ğŸ“ æ•æ„Ÿè¯æ›´æ–°æŠ¥å‘Š - {timestamp}\n\n"
    md_content += "æœ¬æ¬¡æ£€æµ‹åˆ°ä»¥ä¸‹æ–‡ä»¶å‘ç”Ÿå˜åŒ–ï¼š\n\n"
    json_changes = []

    for filename, diff_dict, old_data, new_data in differences:
        if not diff_dict: continue

        md_content += f"## ğŸ“„ `{filename}`\n\n"
        json_change = {"file": filename, "diff": diff_dict}
        has_change_in_file = False

        added = diff_dict.get("added", [])
        if added:
            md_content += "### â• æ–°å¢è§„åˆ™ (by content)\n"
            for item in added:
                md_content += f"- **ID `{item['id']}`**: `{item['value'][:200]}`\n"
            md_content += "\n"
            has_change_in_file = True

        removed = diff_dict.get("removed", [])
        if removed:
            md_content += "### âŒ åˆ é™¤è§„åˆ™ (by content)\n"
            for item in removed:
                md_content += f"- **ID `{item['id']}`**: `{item['value'][:200]}`\n"
            md_content += "\n"
            has_change_in_file = True

        modified = diff_dict.get("modified", {})
        if modified:
            md_content += "### ğŸ” ä¿®æ”¹å…¶ä»–å­—æ®µ\n"
            changed = modified.get("values_changed", {})
            for key, change in changed.items():
                old = change.get('old_value', 'N/A')
                new = change.get('new_value', 'N/A')
                md_content += f"- `{key}`: `{old}` â†’ `{new}`\n"
            md_content += "\n"
            has_change_in_file = True

        if not has_change_in_file:
            md_content += "â„¹ï¸ æ— æ˜¾è‘—å˜åŒ–ã€‚\n\n"

        json_changes.append(json_change)

    json_report = {
        "timestamp": datetime.now().isoformat(),
        "total_files_changed": len(json_changes),
        "changes": json_changes
    }

    print(f"[INFO] æ£€æµ‹åˆ°å˜åŒ–ï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶ï¼š{CHANGELOG_MD} å’Œ {CHANGELOG_JSON}")
    with open(CHANGELOG_MD, "w", encoding="utf-8") as f:
        f.write(md_content)
    with open(CHANGELOG_JSON, "w", encoding="utf-8") as f:
        json.dump(json_report, f, ensure_ascii=False, indent=4)
    
    return True

# ========== ä¸»å‡½æ•° ==========

def main():
    print("[+] å¼€å§‹æ›´æ–°æ•æ„Ÿè¯æ•°æ®...")
    
    cache = load_cache()
    files_to_update = []
    differences = []

    try:
        # --- è·å–æ–° URL ---
        requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)
        session = requests.Session()
        session.headers.update({"Content-Type": "application/x-www-form-urlencoded"})
        
        build_json = {"version": "2.4.0.161787", "sys": "windows", "deviceid": "AA85-636D-18B2-3937-834B-D59E", "network": "wifi", "info": {}}
        
        def get_url(game_id):
            payload = build_json.copy()
            payload["gameid"] = game_id
            resp = session.post(
                f"http://optsdk.gameyw.netease.com/initbox_{game_id}.html",
                data=base64.b64encode(json.dumps(payload).encode('utf-8')).decode('utf-8'),
                verify=False
            )
            resp.raise_for_status()
            data = resp.json()
            if "url" not in data:
                raise Exception(f"{game_id} å“åº”ä¸­æ—  'url' å­—æ®µ: {data}")
            return data["url"]

        x19_url = get_url("x19")
        g79_url = get_url("g79")
        
        # --- æ£€æŸ¥ URL æ˜¯å¦å˜åŒ– ---
        if x19_url == cache.get("x19_url") and g79_url == cache.get("g79_url"):
            print("[INFO] URLs æœªå˜åŒ–ï¼Œæ— éœ€æ›´æ–°ã€‚")
            return

        print("[*] URLs å‘ç”Ÿå˜åŒ–ï¼Œå‡†å¤‡ä¸‹è½½æ–°å†…å®¹...")

        # --- ä¸‹è½½å¹¶è§£å¯† ---
        x19_data = decrypt_content(session.get(x19_url, verify=False).content, "c42bf7f39d479999")
        g79_data = decrypt_content(session.get(g79_url, verify=False).content, "c42bf7f39d476db3")

        new_x19_hash = hash_json(x19_data)
        new_g79_hash = hash_json(g79_data)

        # --- å¯¹æ¯”å†…å®¹ ---
        all_data = [
            ("X19SensitiveWords.json", x19_data),
            ("G79SensitiveWords.json", g79_data),
        ]

        has_content_changed = False
        for name, new_data in all_data:
            old_data = None
            if os.path.exists(name):
                try:
                    with open(name, "r", encoding="utf-8") as f:
                        old_data = json.load(f)
                except Exception as e:
                    print(f"[WARN] æ— æ³•è¯»å–æ—§æ–‡ä»¶ {name}: {e}")
            
            diff = compare_words_by_content(old_data or {}, new_data)

            if diff:
                print(f"[*] {name} å†…å®¹å‘ç”Ÿå˜åŒ–ï¼")
                files_to_update.append((name, new_data))
                differences.append((name, diff, old_data, new_data))
                has_content_changed = True
            else:
                print(f"[INFO] {name} å†…å®¹æœªå‘ç”Ÿå®è´¨æ€§å˜åŒ–ã€‚")
                differences.append((name, None, old_data, new_data))
        
        # --- æ ¹æ®æ˜¯å¦æœ‰å˜åŒ–æ¥ç”ŸæˆæŠ¥å‘Šå¹¶æ›´æ–°æ–‡ä»¶ ---
        if has_content_changed:
            generate_and_save_report(differences)

            # æ›´æ–°æ•æ„Ÿè¯æ–‡ä»¶
            for filename, data in files_to_update:
                content = json.dumps(data, ensure_ascii=False, indent=4)
                with open(filename, "w", encoding="utf-8") as f:
                    f.write(content)
            
            # ä¿å­˜æ–°çŠ¶æ€
            save_cache(x19_url, g79_url, new_x19_hash, new_g79_hash)
            print("\nğŸ‰ è„šæœ¬æ‰§è¡Œå®Œæ¯•ï¼Œæ£€æµ‹åˆ°å†…å®¹æ›´æ–°ã€‚")
        else:
            print("[INFO] æ‰€æœ‰æ–‡ä»¶å‡æ— å®è´¨å˜åŒ–ï¼Œæ— éœ€æ›´æ–°æ–‡ä»¶æˆ–æŠ¥å‘Šã€‚")
            # å³ä½¿å†…å®¹æ²¡å˜ï¼ŒURLä¹Ÿå¯èƒ½å˜äº†ï¼Œæ‰€ä»¥ä¾ç„¶è¦ä¿å­˜æ–°URLçš„ç¼“å­˜
            save_cache(x19_url, g79_url, new_x19_hash, new_g79_hash)

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"\n[CRITICAL] æ‰§è¡Œå¤±è´¥: {e}")
        exit(1)

if __name__ == "__main__":
    main()
