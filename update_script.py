# update_script.py
# åŠŸèƒ½ï¼šè‡ªåŠ¨è§£å¯†ã€å¯¹æ¯”ã€æ›´æ–°ç½‘æ˜“æ•æ„Ÿè¯ï¼Œå¹¶ç”Ÿæˆå˜åŒ–æŠ¥å‘Š
# ç”¨é€”ï¼šé…åˆ GitHub Actions è‡ªåŠ¨åŒ–è¿è¡Œ

import re
import json
import base64
import requests
from Crypto.Cipher import ARC4
import os
from deepdiff import DeepDiff
from hashlib import md5
from datetime import datetime

# ========== é…ç½® ==========
CACHE_FILE = "last_urls.json"        # ç¼“å­˜ä¸Šä¸€æ¬¡çš„ URL å’Œå“ˆå¸Œ
CHANGELOG_MD = "CHANGELOG.md"        # äººç±»å¯è¯»çš„å˜åŒ–æŠ¥å‘Š
CHANGELOG_JSON = "changes.json"      # æœºå™¨å¯è¯»çš„ç»“æ„åŒ–å·®å¼‚
GITHUB_OWNER = "daijunhaoMinecraft"
GITHUB_REPO = "NeteaseSensitiveWordsProject"
GITHUB_BRANCH = "main"

# ========== å·¥å…·å‡½æ•° ==========

def decode_pcre_unicode_in_obj(obj):
    """
    Recursively decode strings with PCRE-style Unicode escape sequences (e.g., \\x{abcd}).
    """
    if isinstance(obj, dict):
        return {k: decode_pcre_unicode_in_obj(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [decode_pcre_unicode_in_obj(elem) for elem in obj]
    elif isinstance(obj, str):
        def replace_match(match):
            hex_code = match.group(1)
            return chr(int(hex_code, 16))
        return re.sub(r'\\x\{([0-9a-fA-F]+)\}', replace_match, obj)
    else:
        return obj

def decrypt_content(encrypted_content: bytes, key: str) -> dict:
    """è§£å¯†å¹¶è¿”å›å­—å…¸"""
    try:
        encrypted_data = base64.b64decode(encrypted_content)
        cipher = ARC4.new(key.encode('utf-8'))
        decrypted_data = cipher.decrypt(encrypted_data)
        raw_text = decrypted_data.decode('utf-8')
        parsed = json.loads(raw_text)
        return decode_pcre_unicode_in_obj(parsed)
    except Exception as e:
        print(f"[ERROR] è§£å¯†å¤±è´¥: {e}")
        raise

def load_cache():
    """åŠ è½½ä¸Šä¸€æ¬¡çš„çŠ¶æ€ï¼ˆURL + å“ˆå¸Œï¼‰"""
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            # è¡¥å…¨ç¼ºå¤±å­—æ®µ
            for key in ["x19_url", "g79_url", "x19_hash", "g79_hash"]:
                if key not in data:
                    data[key] = None
            return data
        except Exception as e:
            print(f"[WARN] æ— æ³•è¯»å–ç¼“å­˜æ–‡ä»¶: {e}")
    return {"x19_url": None, "g79_url": None, "x19_hash": None, "g79_hash": None}

def save_cache(x19_url, g79_url, x19_hash, g79_hash):
    """ä¿å­˜å½“å‰çŠ¶æ€"""
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump({
            "x19_url": x19_url,
            "g79_url": g79_url,
            "x19_hash": x19_hash,
            "g79_hash": g79_hash,
            "updated_at": datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=4)

def hash_json(data):
    """ç”Ÿæˆ JSON å†…å®¹çš„ç¨³å®šå“ˆå¸Œ"""
    return md5(json.dumps(data, sort_keys=True, ensure_ascii=False, separators=(',', ':')).encode('utf-8')).hexdigest()

def get_file_sha(owner, repo, path, token, branch="main"):
    """è·å–æ–‡ä»¶å½“å‰ SHA"""
    url = f"https://api.github.com/repos/{owner}/{repo}/contents/{path}"
    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/vnd.github.v3+json"
    }
    params = {"ref": branch}
    try:
        resp = requests.get(url, headers=headers, params=params)
        if resp.status_code == 200:
            return resp.json()["sha"]
        elif resp.status_code == 404:
            return None
        else:
            print(f"[ERROR] è·å– SHA å¤±è´¥: {resp.status_code}")
            return None
    except Exception as e:
        print(f"[ERROR] è¯·æ±‚å¤±è´¥: {e}")
        return None

def update_github_file(owner, repo, filepath, content, token, branch="main", commit_msg="Auto update"):
    """åˆ›å»ºæˆ–æ›´æ–° GitHub æ–‡ä»¶"""
    url = f"https://api.github.com/repos/{owner}/{repo}/contents/{filepath}"
    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/vnd.github.v3+json"
    }

    sha = get_file_sha(owner, repo, filepath, token, branch)
    encoded_content = base64.b64encode(content.encode('utf-8')).decode('utf-8')
    payload = {"message": commit_msg, "content": encoded_content, "branch": branch}
    if sha:
        payload["sha"] = sha

    resp = requests.put(url, headers=headers, json=payload)
    if resp.status_code in (200, 201):
        print(f"[SUCCESS] æˆåŠŸæ›´æ–° {filepath}")
        return True
    else:
        print(f"[ERROR] æ›´æ–°å¤±è´¥ {filepath}: {resp.status_code}")
        try:
            print(resp.json())
        except:
            print(resp.text)
        return False

# ã€ä¿®å¤ã€‘å‡½æ•°ç°åœ¨æ¥æ”¶åŸå§‹æ•°æ®å­—å…¸(data_obj)æ¥æŸ¥æ‰¾å€¼
def diff_path_to_value(data_obj, path):
    """
    ä» deepdiff è·¯å¾„(e.g., "root['key'][0]")åœ¨ç»™å®šçš„æ•°æ®å¯¹è±¡ä¸­æå–å€¼ç”¨äºæ˜¾ç¤ºã€‚
    """
    try:
        # ã€ä¼˜åŒ–ã€‘æ›´ç¨³å¥çš„è·¯å¾„è§£æ
        keys = re.findall(r"\[\'(.*?)\'\]|\[(\d+)\]", path)
        value = data_obj
        for key_tuple in keys:
            key_str, key_int_str = key_tuple
            key = key_str if key_str else int(key_int_str)

            if isinstance(value, dict):
                value = value.get(key)
            elif isinstance(value, list) and isinstance(key, int):
                value = value[key]
            else:
                return "è·¯å¾„è§£æå¤±è´¥" # Path parsing failed
        return str(value)[:200]  # æˆªæ–­è¿‡é•¿å†…å®¹
    except Exception as e:
        print(f"[DEBUG] diff_path_to_value failed for path '{path}': {e}")
        return "å€¼æå–å¤±è´¥" # Value extraction failed

# ã€ä¿®å¤ã€‘å‡½æ•°ç­¾åå’Œå†…éƒ¨é€»è¾‘å·²æ›´æ–°
def generate_changes_report(differences):
    """
    ç”Ÿæˆç»Ÿä¸€çš„å˜åŒ–æŠ¥å‘Š
    :param differences: [(filename, diff_obj, old_data, new_data), ...]
    """
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    if not any(d[1] for d in differences): # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„ diff å¯¹è±¡
        md_content = f"# ğŸ“ æ•æ„Ÿè¯æ›´æ–°æŠ¥å‘Š - {timestamp}\n\nâœ… æœ¬æ¬¡è¿è¡Œæœªæ£€æµ‹åˆ°ä»»ä½•å†…å®¹å˜åŒ–ã€‚\n"
        json_report = {
            "timestamp": datetime.now().isoformat(),
            "total_files_changed": 0,
            "changes": []
        }
    else:
        md_content = f"# ğŸ“ æ•æ„Ÿè¯æ›´æ–°æŠ¥å‘Š - {timestamp}\n\n"
        md_content += "æœ¬æ¬¡æ£€æµ‹åˆ°ä»¥ä¸‹æ–‡ä»¶å‘ç”Ÿå˜åŒ–ï¼š\n\n"
        json_changes = []

        # ã€ä¿®å¤ã€‘è§£åŒ…å…ƒç»„ä»¥è·å– old_data å’Œ new_data
        for filename, diff, old_data, new_data in differences:
            if not diff: continue # å¦‚æœæ²¡æœ‰å·®å¼‚ï¼Œè·³è¿‡

            diff_dict = diff.to_dict()

            # ã€ä¿®å¤ã€‘å°† diff_dict ä¸­çš„ set-like å¯¹è±¡è½¬æ¢ä¸º listï¼Œä½¿å…¶å¯ä»¥è¢« JSON åºåˆ—åŒ–
            serializable_diff_dict = {}
            for key, value in diff_dict.items():
                if isinstance(value, (set, frozenset)) or type(value).__name__ == 'SetOrdered':
                    # æ’åºä»¥è·å¾—ä¸€è‡´çš„è¾“å‡º
                    try:
                        serializable_diff_dict[key] = sorted(list(value))
                    except TypeError: # å¦‚æœå…ƒç´ ä¸å¯æ’åº
                        serializable_diff_dict[key] = list(value)
                else:
                    serializable_diff_dict[key] = value

            md_content += f"## ğŸ“„ `{filename}`\n\n"
            json_change = {"file": filename, "diff": serializable_diff_dict}
            has_change = False

            # æ–°å¢
            added = diff_dict.get("dictionary_item_added", [])
            if added:
                md_content += "### â• æ–°å¢è§„åˆ™\n"
                for item in added:
                    # ã€ä¿®å¤ã€‘ä» new_data ä¸­æŸ¥æ‰¾æ–°å¢çš„å€¼
                    value_str = diff_path_to_value(new_data, item)
                    md_content += f"- `{item}`: {value_str}\n"
                md_content += "\n"
                has_change = True

            # åˆ é™¤
            removed = diff_dict.get("dictionary_item_removed", [])
            if removed:
                md_content += "### âŒ åˆ é™¤è§„åˆ™\n"
                for item in removed:
                    # ã€ä¿®å¤ã€‘ä» old_data ä¸­æŸ¥æ‰¾è¢«åˆ é™¤çš„å€¼
                    value_str = diff_path_to_value(old_data, item)
                    md_content += f"- `{item}`: {value_str}\n"
                md_content += "\n"
                has_change = True

            # ä¿®æ”¹
            changed = diff_dict.get("values_changed", {})
            if changed:
                md_content += "### ğŸ” ä¿®æ”¹è§„åˆ™\n"
                for key, change in changed.items():
                    old = change.get('old_value', 'N/A')
                    new = change.get('new_value', 'N/A')
                    md_content += f"- `{key}`: `{old}` â†’ `{new}`\n"
                md_content += "\n"
                has_change = True

            # ç±»å‹å˜æ›´
            type_changed = diff_dict.get("type_changes", {})
            if type_changed:
                md_content += "### âš ï¸ ç±»å‹å˜æ›´\n"
                for key, change in type_changed.items():
                    old_t = change.get('old_type', 'N/A')
                    new_t = change.get('new_type', 'N/A')
                    md_content += f"- `{key}`: `{old_t}` â†’ `{new_t}`\n"
                md_content += "\n"
                has_change = True

            if not has_change:
                md_content += "â„¹ï¸ æ— æ˜¾è‘—å˜åŒ–ï¼ˆå¯èƒ½ä¸ºé¡ºåºè°ƒæ•´æˆ–æœªè·Ÿè¸ªçš„ç±»å‹ï¼‰\n\n"

            json_changes.append(json_change)

        json_report = {
            "timestamp": datetime.now().isoformat(),
            "total_files_changed": len(json_changes),
            "changes": json_changes
        }

    with open(CHANGELOG_MD, "w", encoding="utf-8") as f:
        f.write(md_content)

    with open(CHANGELOG_JSON, "w", encoding="utf-8") as f:
        json.dump(json_report, f, ensure_ascii=False, indent=4)

    print(f"[INFO] å˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆï¼š{CHANGELOG_MD} å’Œ {CHANGELOG_JSON}")

# ========== ä¸»å‡½æ•° ==========

def main():
    print("[+] å¼€å§‹æ›´æ–°æ•æ„Ÿè¯æ•°æ®...")

    GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
    if not GITHUB_TOKEN:
        raise Exception("âŒ GITHUB_TOKEN æœªè®¾ç½®ï¼è¯·æ£€æŸ¥ Actions Secretsã€‚")

    cache = load_cache()
    old_x19_url = cache.get("x19_url")
    old_g79_url = cache.get("g79_url")

    files_to_update = []
    differences = []  # ã€ä¼˜åŒ–ã€‘ç°åœ¨å­˜å‚¨ (filename, diff_obj, old_data, new_data)

    try:
        # --- è·å–æ–° URL ---
        build_json_x19 = {
            "version": "2.4.0.161787",
            "sys": "windows",
            "deviceid": "AA85-636D-18B2-3937-834B-D59E",
            "gameid": "x19",
            "network": "wifi",
            "info": {}
        }
        build_json_g79 = build_json_x19.copy()
        build_json_g79["gameid"] = "g79"
        
        # ã€ä¼˜åŒ–ã€‘ä½¿ç”¨ requests.Session å’Œå…³é—­ InsecureRequestWarning
        requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)
        session = requests.Session()
        session.headers.update({"Content-Type": "application/x-www-form-urlencoded"})

        x19_resp = session.post(
            "http://optsdk.gameyw.netease.com/initbox_x19.html",
            data=base64.b64encode(json.dumps(build_json_x19).encode('utf-8')).decode('utf-8'),
            verify=False
        )
        x19_resp.raise_for_status()
        x19_data_resp = x19_resp.json()
        if "url" not in x19_data_resp:
            raise Exception(f"å“åº”ä¸­æ—  'url' å­—æ®µ: {x19_data_resp}")
        x19_url = x19_data_resp["url"]

        g79_resp = session.post(
            "http://optsdk.gameyw.netease.com/initbox_g79.html",
            data=base64.b64encode(json.dumps(build_json_g79).encode('utf-8')).decode('utf-8'),
            verify=False
        )
        g79_resp.raise_for_status()
        g79_data_resp = g79_resp.json()
        if "url" not in g79_data_resp:
            raise Exception(f"å“åº”ä¸­æ—  'url' å­—æ®µ: {g79_data_resp}")
        g79_url = g79_data_resp["url"]

        # --- æ£€æŸ¥ URL æ˜¯å¦å˜åŒ– ---
        if x19_url == old_x19_url and g79_url == old_g79_url:
            print("[INFO] URLs æœªå˜åŒ–ï¼Œæ— éœ€æ›´æ–°ã€‚")
            generate_changes_report([]) # ç”Ÿæˆç©ºæŠ¥å‘Š
            return

        print("[*] URLs å‘ç”Ÿå˜åŒ–ï¼Œå‡†å¤‡ä¸‹è½½æ–°å†…å®¹...")

        # --- ä¸‹è½½å¹¶è§£å¯† ---
        x19_encrypted = session.get(x19_url, verify=False).content
        g79_encrypted = session.get(g79_url, verify=False).content

        x19_data = decrypt_content(x19_encrypted, "c42bf7f39d479999")
        g79_data = decrypt_content(g79_encrypted, "c42bf7f39d476db3")

        x19_hash = hash_json(x19_data)
        g79_hash = hash_json(g79_data)

        # --- æ¯”è¾ƒå†…å®¹å˜åŒ– ---
        for name, new_data, url in [
            ("X19SensitiveWords.json", x19_data, x19_url),
            ("G79SensitiveWords.json", g79_data, g79_url)
        ]:
            old_data = None
            if os.path.exists(name):
                try:
                    with open(name, "r", encoding="utf-8") as f:
                        old_data = json.load(f)
                except Exception as e:
                    print(f"[WARN] æ— æ³•è¯»å–æ—§æ–‡ä»¶ {name}: {e}")

            if old_data is None:
                print(f"[INFO] é¦–æ¬¡è¿è¡Œæˆ– {name} ä¸å­˜åœ¨ï¼Œè§†ä¸ºæ–°å¢ã€‚")
                files_to_update.append((name, new_data, url))
                # ã€ä¿®å¤ã€‘ä¸ºæŠ¥å‘Šæ·»åŠ å ä½ç¬¦
                diff = DeepDiff({}, new_data, ignore_order=True)
                differences.append((name, diff, {}, new_data))
            else:
                diff = DeepDiff(old_data, new_data, ignore_order=True)
                if diff:
                    print(f"[*] {name} å†…å®¹å‘ç”Ÿå˜åŒ–ï¼")
                    files_to_update.append((name, new_data, url))
                    # ã€ä¿®å¤ã€‘å°† old_data å’Œ new_data æ·»åŠ åˆ°å…ƒç»„ä¸­
                    differences.append((name, diff, old_data, new_data))
                else:
                    print(f"[INFO] {name} å†…å®¹æœªå˜åŒ–ï¼ˆåŸºäºç»“æ„å¯¹æ¯”ï¼‰ï¼Œè·³è¿‡ã€‚")
                    # ã€ä¼˜åŒ–ã€‘å³ä½¿å†…å®¹ä¸å˜ï¼Œä¹Ÿæ·»åŠ ä¸€ä¸ªç©ºçš„ diffï¼Œä»¥ä¾¿æŠ¥å‘Šç”Ÿæˆå™¨èƒ½æ­£ç¡®å¤„ç†
                    differences.append((name, None, old_data, new_data))

        # --- ç”Ÿæˆç»Ÿä¸€å˜åŒ–æŠ¥å‘Š ---
        generate_changes_report(differences)

        # --- ä»…å½“æœ‰æ–‡ä»¶è¦æ›´æ–°æ—¶æ‰æäº¤ ---
        if not files_to_update:
            print("[INFO] æ‰€æœ‰æ–‡ä»¶å‡æ— å®è´¨å˜åŒ–ï¼Œæ— éœ€æäº¤ã€‚")
            save_cache(x19_url, g79_url, x19_hash, g79_hash)
            return

        # --- æ›´æ–° GitHub æ–‡ä»¶ ---
        all_success = True
        for filename, data, url in files_to_update:
            content = json.dumps(data, ensure_ascii=False, indent=4)
            success = update_github_file(
                owner=GITHUB_OWNER,
                repo=GITHUB_REPO,
                filepath=filename,
                content=content,
                token=GITHUB_TOKEN,
                branch=GITHUB_BRANCH,
                commit_msg=f"ğŸ”„ Update {filename} (source updated)"
            )
            if success:
                # æœ¬åœ°ä¹Ÿå†™å…¥ä¸€ä»½ï¼Œç¡®ä¿ä¸‹æ¬¡è¿è¡Œæ—¶ old_data æ˜¯æœ€æ–°çš„
                with open(filename, "w", encoding="utf-8") as f:
                    f.write(content)
            all_success &= success
        
        # ã€ä¼˜åŒ–ã€‘æ— è®ºæ›´æ–°æ˜¯å¦æˆåŠŸï¼Œéƒ½è¦æ›´æ–° GitHub ä¸Šçš„æŠ¥å‘Šæ–‡ä»¶
        for report_file in [CHANGELOG_MD, CHANGELOG_JSON]:
            if os.path.exists(report_file):
                with open(report_file, "r", encoding="utf-8") as f:
                    report_content = f.read()
                update_github_file(
                    owner=GITHUB_OWNER,
                    repo=GITHUB_REPO,
                    filepath=report_file,
                    content=report_content,
                    token=GITHUB_TOKEN,
                    branch=GITHUB_BRANCH,
                    commit_msg=f"ğŸ“„ Update changelog for {datetime.now().strftime('%Y-%m-%d')}"
                )

        if all_success:
            print("\nğŸ‰ æ‰€æœ‰å˜æ›´æ–‡ä»¶å·²æˆåŠŸæ›´æ–°ï¼")
            save_cache(x19_url, g79_url, x19_hash, g79_hash)
        else:
            print("\nâŒ éƒ¨åˆ†æˆ–å…¨éƒ¨æ–‡ä»¶æ›´æ–°å¤±è´¥ã€‚")
            exit(1)

    except requests.exceptions.RequestException as e:
        print(f"\n[NETWORK ERROR] ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
        exit(1)
    except json.JSONDecodeError as e:
        print(f"\n[JSON ERROR] JSON è§£æå¤±è´¥: {e}")
        exit(1)
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"\n[CRITICAL] æ‰§è¡Œå¤±è´¥: {e}")
        exit(1)

if __name__ == "__main__":
    main()
